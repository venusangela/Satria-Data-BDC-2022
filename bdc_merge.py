# -*- coding: utf-8 -*-
"""BDC-merge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14G4Xk0M7K8hXk6RiZez7W-lbVQts0dZ-

# Import and Prep
"""

# Read Text Files with Pandas using read_csv()
  
# importing pandas
import pandas as pd
  
# read text file into pandas DataFrame
df = pd.read_csv("/content/drive/MyDrive/BDC/BDC Satria Data 2022/train_fktp.txt", sep=",", header=None, names = ['no_peserta', 'no_kel', 'bobot', 'id_kunj','tgl_datang', 'tgl_pulang', 
                                                                                                                 'prov', 'kab', 'kepemilikan', 'jenis', 'tipe', 'tingkat_pelayanan', 
                                                                                                                 'jenis_poli', 'segmen_peserta', 'kode_ICD', 'kode_ICD3', 'kode_ICD4', 
                                                                                                                 'ICD4_diagnosis', 'prov_rujukan', 'kab_rujukan', 'kepemilikan_rujukan',
                                                                                                                 'jenis_rujukan', 'tipe_rujukan' , 'poli_rujukan', 'jenis_kunjungan', 
                                                                                                                 'status_pulang'])
# df = pd.read_csv("/content/drive/MyDrive/BDC/BDC Satria Data 2022/test_fktp.txt", sep=",", header=None,
#                  names = ['no_peserta', 'no_kel', 'bobot', 'id_kunj','tgl_datang', 'tgl_pulang', 
#                           'prov', 'kab', 'kepemilikan', 'jenis', 'tipe', 'tingkat_pelayanan', 
#                           'jenis_poli', 'segmen_peserta', 'kode_ICD', 'kode_ICD3', 'kode_ICD4', 
#                           'ICD4_diagnosis', 'prov_rujukan', 'kab_rujukan', 'kepemilikan_rujukan',
#                           'jenis_rujukan', 'tipe_rujukan' , 'poli_rujukan', 'jenis_kunjungan'])
# display DataFrame
df.info()

from google.colab import drive
drive.mount('/content/drive')

df_train = pd.read_csv("/content/drive/MyDrive/BDC/train-siap-encode.csv")

df_train.info()

df = df_train.drop(['Unnamed: 0'], axis=1)
df.info()



df = df_train

header = ['no_peserta', 'no_kel', 'bobot', 'id_kunj','tgl_datang', 'tgl_pulang', 'prov', 'kab', 'kepemilikan', 'jenis', 'tipe', 'tingkat_pelayanan', 'jenis_poli', 'segmen_peserta', 'kode_ICD', 'kode_ICD3', 'kode_ICD4', 'ICD4_diagnosis', 'prov_rujukan', 'kab_rujukan', 'kepemilikan_rujukan', 'jenis_rujukan', 'tipe_rujukan' , 'poli_rujukan', 'jenis_kunjungan', 'status_pulang']

df.describe()

df.isnull().sum()

df.head()

df.info()

"""#Cleaning

Change datetime to pandas format
"""

df['tgl_datang'] = pd.to_datetime(df['tgl_datang'], format="%Y-%m-%d")

df['tgl_pulang'] = pd.to_datetime(df['tgl_pulang'], format="%Y-%m-%d")

"""Check Imbalance"""

df.groupby('status_pulang').count()

"""check pattern of some columns"""

#checking uniqueness and pattern of no keluarga
ax = []
for i in df['no_kel']:
  # if len(str(i)) >= 2 and len(str(i)) <= 7:
    # print(i)
  ax.append(len(str(i)))
print(min(ax), max(ax))

# check uniqueness and pattern of id kunjungan
ax = []
for i in df['id_kunj']:
  ax.append(len(str(i)))
print(min(ax), max(ax))

# print(df['kode_ICD4'].unique())
ax = []
for i in df['kode_ICD4']:
  ax.append(len(str(i)))
print(min(ax), max(ax))

len(df['no_kel']) - len(df['no_kel'].unique())

for a in header:
  print(a)
  print(df[a].unique())
  print(len(df[a].unique()))
  print(len(df[a]) - len(df[a].unique()))

"""### NaN Handler"""

df['jenis_poli'].mode()

df['kode_ICD4'] = df['kode_ICD4'].astype('str')

#kolom 12 diisi mode
df['jenis_poli'] = df['jenis_poli'].fillna(1.0)
#kolom 15 diisi kode_ICD4[:3]
icd3 = []
for i in df['kode_ICD4']:
  icd3.append(i[:3])
df['kode_ICD3'] = icd3

icd3

len(df['kode_ICD4'][0])

df.isna().sum()

"""## Drop"""

df = df.drop(['ICD4_diagnosis'], axis=1)
df.info()

"""# Feature Engineering

##Jumlah per peserta
"""

df.groupby(['no_peserta']).head()

"""jumlah kunjungan"""

df.groupby(['no_peserta']).size()

dup_id = df.groupby(['no_peserta']).size()
dup_id_pes = []
for i in df['no_peserta']:
  dup_id_pes.append(dup_id[i])
len(dup_id_pes)

"""jumlah pulang tidak sehat dan sehat"""

pes_pul = pd.DataFrame(df.groupby(['no_peserta', 'status_pulang']).size().reset_index())
pes_pul

pes_pul.info()

tdk_sehat = []
sehat = []
for i in range(len(df['no_peserta'])):
  print(i)
  if len(pes_pul.loc[(pes_pul['no_peserta'] == df['no_peserta'][i]) & (pes_pul['status_pulang'] == 'Belum_Sehat')]) != 0:
    tdk_sehat.append(pes_pul.loc[(pes_pul['no_peserta'] == df['no_peserta'][i]) & (pes_pul['status_pulang'] == 'Belum_Sehat')][0])
  else:
    tdk_sehat.append(0)
  if len(pes_pul.loc[(pes_pul['no_peserta'] == df['no_peserta'][i]) & (pes_pul['status_pulang'] == 'Sehat')]) != 0:
    sehat.append(pes_pul.loc[(pes_pul['no_peserta'] == df['no_peserta'][i]) & (pes_pul['status_pulang'] == 'Sehat')][0])
  else:
    sehat.append(0)
print(len(tdk_sehat), len(sehat))

df['jum_kunj'] = dup_id_pes
# df['pul_sehat'] = sehat
# df['pul_tida'] = tdk_sehat

'9999' in df['kode_ICD4']

huruf = []
angka = []
for i in df['kode_ICD4']:
  angka.append(i[1:])
  huruf.append(i[0])

df['kodeICD_huruf'] = huruf

df['kodeICD_angka'] = angka

df.isna().sum()

df['kodeICD_angka'] = df['kodeICD_angka'].astype('float')

hari_inap = (df['tgl_pulang'] - df['tgl_datang']).dt.days
df['jml_hari'] = hari_inap

df.info()

df['tgl_datang'] = pd.to_datetime(df.tgl_datang, format='%Y-%m-%d').values.astype("float64")
df['tgl_pulang'] = pd.to_datetime(df.tgl_datang, format='%Y-%m-%d').values.astype("float64")

df.to_csv('/content/drive/MyDrive/BDC/test-siap-encode.csv')

"""# EDA

## Encoding
"""

import pandas as pd

test = pd.read_csv("/content/drive/MyDrive/BDC/test-siap-encode.csv", sep=",")
test.info()

train = pd.read_csv("/content/drive/MyDrive/BDC/train-siap-encode.csv", sep=",")
train.info()

import pandas as pd
test = pd.read_csv('/content/drive/MyDrive/BDC/test-icd3-icd4-jenis_kunj-encode.csv')

from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder

list_df = ['kode_ICD_huruf', 'kode_ICD_angka']
hasil_encode_train = pd.DataFrame()

df['kodeICD_huruf'] = df['kodeICD_huruf'].astype('str')
df['kodeICD_angka'] = df['kodeICD_angka'].astype('str')

df.info()

list_df = ['kode_ICD4', 'kode_ICD3','jenis_kunjungan']
hasil_encode_test = pd.DataFrame()
hasil_encode_train = pd.DataFrame()

train['kode_ICD4'] = train['kode_ICD4'].astype('str')
test['kode_ICD4'] = train['kode_ICD4'].astype('str')
train['kode_ICD3'] = train['kode_ICD3'].astype('str')
test['kode_ICD3'] = train['kode_ICD3'].astype('str')
train['kode_ICD3'] = train['kode_ICD3'].astype('str')
test['kode_ICD3'] = train['kode_ICD3'].astype('str')

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
for i in list_df:
    print(i)
    le.fit(list(set(list(train[i].unique()) + list(test[i].unique()))))
    # list(le.classes_)
    hasil_encode_test[i] = le.transform(test[i])
    hasil_encode_train[i] = le.transform(train[i])

hasil_encode_test.info()

test['id_kunj'] = test['id_kunj'].astype('str')

#perform label encoding
test[['no_kel_enc', 'id_kunj_enc']] = test[['no_kel', 'id_kunj']].apply(LabelEncoder().fit_transform)

#view udpated DataFrame
# print(df)

test[['kode_ICD3_enc', 'kode_ICD4_enc', 'jenis_kunjungan_enc']] = hasil_encode_test

test = test.drop(['no_kel', 'id_kunj', 'kode_ICD3', 'kode_ICD4', 'jenis_kunjungan'], axis=1)
test.info()

hasil_encode_train.to_csv('/content/drive/MyDrive/BDC/train-icd3-icd4-jenis_kunj-encode.csv')
test.to_csv('/content/drive/MyDrive/BDC/test-icd3-icd4-jenis_kunj-encode.csv')

test['kodeICD_huruf'] = test['kodeICD_huruf'].astype('str')

test.info()

encoder = OneHotEncoder(handle_unknown='ignore')
encoder_df = pd.DataFrame(encoder.fit_transform(test[['prov']]).toarray())
encoder_df.columns = encoder.get_feature_names(['Prov'])
test = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['kepemilikan']]).toarray())
encoder_df.columns = encoder.get_feature_names(['kepemilikan'])
test = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['jenis']]).toarray())
encoder_df.columns = encoder.get_feature_names(['jenis'])
test = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['tipe']]).toarray())
encoder_df.columns = encoder.get_feature_names(['tipe'])
test = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['tingkat_pelayanan']]).toarray())
encoder_df.columns = encoder.get_feature_names(['tingkat_pelayanan'])
test = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['jenis_poli']]).toarray())
encoder_df.columns = encoder.get_feature_names(['jenis_poli'])
test = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['segmen_peserta']]).toarray())
encoder_df.columns = encoder.get_feature_names(['segmen_peserta'])
test = test.join(encoder_df)

encoder = OneHotEncoder(handle_unknown='ignore')
encoder_df = pd.DataFrame(encoder.fit_transform(test[['prov_rujukan']]).toarray())
encoder_df.columns = encoder.get_feature_names(['prov_rujukan'])
test = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['kepemilikan_rujukan']]).toarray())
encoder_df.columns = encoder.get_feature_names(['kepemilikan_rujukan'])
test = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['jenis_rujukan']]).toarray())
encoder_df.columns = encoder.get_feature_names(['jenis_rujukan'])
test = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['tipe_rujukan']]).toarray())
encoder_df.columns = encoder.get_feature_names(['tipe_rujukan'])
test = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['kodeICD_huruf']]).toarray())
encoder_df.columns = encoder.get_feature_names(['kodeICD_huruf'])
test = test.join(encoder_df)

test = test.drop(['Unnamed: 0', 'prov', 'kepemilikan', 'jenis', 'tipe', 'tingkat_pelayanan', 'jenis_poli', 'segmen_peserta', 'prov_rujukan', 'kepemilikan_rujukan', 'jenis_rujukan', 'tipe_rujukan', 'kodeICD_huruf'], axis=1)

test.to_csv('/content/drive/MyDrive/BDC/test-encoded.csv')

test.info()

test['id_kunj'] = test['id_kunj'].astype('str')

"""hilmi"""

# encoder = OneHotEncoder(handle_unknown='ignore')
# encoder_df = pd.DataFrame(encoder.fit_transform(test[['id_kunj']]).toarray())
# encoder_df.columns = encoder.get_feature_names(['id_kunj'])
# df = test.join(encoder_df)

# encoder_df = pd.DataFrame(encoder.fit_transform(test[['kode_ICD4']]).toarray())
# encoder_df.columns = encoder.get_feature_names(['kode_ICD4'])
# df = test.join(encoder_df)

# encoder_df = pd.DataFrame(encoder.fit_transform(test[['kode_ICD3']]).toarray())
# encoder_df.columns = encoder.get_feature_names(['kode_ICD3'])
# df = test.join(encoder_df)

# encoder_df = pd.DataFrame(encoder.fit_transform(test[['jenis_kunjungan']]).toarray())
# encoder_df.columns = encoder.get_feature_names(['jenis_kunjungan'])
# df = test.join(encoder_df)

encoder = OneHotEncoder(handle_unknown='ignore')
encoder_df = pd.DataFrame(encoder.fit_transform(test[['jenis_poli']]).toarray())
encoder_df.columns = encoder.get_feature_names(['jenis_poli'])
df = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['kodeICD_huruf']]).toarray())
encoder_df.columns = encoder.get_feature_names(['kodeICD_huruf'])
df = test.join(encoder_df)

encoder_df = pd.DataFrame(encoder.fit_transform(test[['kodeICD_angka']]).toarray())
encoder_df.columns = encoder.get_feature_names(['kodeICD_angka'])
df = test.join(encoder_df)

"""## Correlation"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from dython import nominal
import scipy.stats as stats

df = pd.read_csv("csv-encode.csv", sep=",")

df = df.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1'], axis=1)

df['tgl_datang'] = pd.to_datetime(df.tgl_datang, format='%Y-%m-%d')
df['tgl_pulang'] = pd.to_datetime(df.tgl_datang, format='%Y-%m-%d')

x = df.drop(['status_pulang_enc', 'ICD4_diagnosis', 'kodeICD_huruf'], axis=1)

"""### Pearson Correlation"""

p_corr = df.drop(['ICD4_diagnosis', 'kodeICD_huruf'], axis=1).corr()

pearson = pd.DataFrame(p_corr['status_pulang_enc'])
pearson

p_sort = pearson.sort_values(by=['status_pulang_enc'], ascending=False)
p_sort

p_sort.loc[p_sort['status_pulang_enc'] >= 0.5]

"""### Theil U Correlation"""

theilu = pd.DataFrame(index=['status_pulang_enc'],columns=x.columns)
columns = x.columns
for j in range(0,len(columns)):
    u = nominal.theils_u(df['status_pulang_enc'].tolist(),x[columns[j]].tolist())
    theilu.loc[:,columns[j]] = u
theilu.fillna(value=np.nan,inplace=True)
plt.figure(figsize=(20,1))
sns.heatmap(theilu,annot=True,fmt='.2f')
plt.show()

t_transpose = theilu.transpose().sort_values(by=['status_pulang_enc'], ascending=False)
t_transpose

t_transpose.loc[t_transpose['status_pulang_enc'] >= 0.5]

"""### Cramers V Correlation"""

def cramers_corrected_stat(confusion_matrix):
    """ calculate Cramers V statistic for categorical-categorical association.
        uses correction from Bergsma and Wicher, 
        Journal of the Korean Statistical Society 42 (2013): 323-328
    """
    chi2 = stats.chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum().sum()
    phi2 = chi2/n
    r,k = confusion_matrix.shape
    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    
    rcorr = r - ((r-1)**2)/(n-1)
    kcorr = k - ((k-1)**2)/(n-1)
    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))

cramersv_1 = pd.DataFrame(index=['status_pulang_enc'],columns=x.columns)
columns = x.columns
for i in range(0,len(columns)):
    # print(i)
    u = cramers_corrected_stat(pd.crosstab(df['status_pulang_enc'], x[columns[i]]))
    cramersv_1.loc[:,columns[i]] = u
cramersv_1.fillna(value=np.nan,inplace=True)
plt.figure(figsize=(20,1))
sns.heatmap(cramersv_1,annot=True,fmt='.2f')
plt.show()

c1_transpose = cramersv_1.transpose().sort_values(by=['status_pulang_enc'], ascending=False)
c1_transpose

c1_transpose.loc[c1_transpose['status_pulang_enc'] >= 0.5]

"""### Chi-Square Correlation"""

def chi_square(col1,col2):
    contingency = np.array(pd.crosstab(col1, col2))
    val = stats.chi2_contingency(contingency)
    return val

"""null hypothesis: col1 and col2 are independent. There are no correlation"""

chisquare = pd.DataFrame(index=['status_pulang_enc', 'chi_square', 'p_value'],columns=x.columns)
columns = x.columns
sig_level = 0.05
for j in range(0,len(columns)):
    print(j)
    u = chi_square(df['status_pulang_enc'],x[columns[j]])
    if u[1] > sig_level:
        chisquare.loc['status_pulang_enc'][columns[j]] = 0 #null hypothesis accepted
    else:
        chisquare.loc['status_pulang_enc'][columns[j]] = 1 #null hypothesis rejected
    chisquare.loc['chi_square'][columns[j]] = u[0]
    chisquare.loc['p_value'][columns[j]] = u[1]

chisquare.fillna(value=np.nan,inplace=True)
plt.figure(figsize=(20,1))
sns.heatmap(chisquare,annot=True,fmt='.2f')
plt.show()

chisquare_transpose = chisquare.transpose().sort_values(by=['status_pulang_enc'], ascending=False)
chisquare_transpose

"""# Modelling"""

#Import Libraries
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
import numpy as np
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
import statistics as stat
from sklearn.metrics import accuracy_score
#from sklearn.metrics import confusion_matrix
from imblearn.over_sampling import SMOTE, ADASYN
from collections import Counter
# Modules used for assessing the performance of the model
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix

#Performance Report
def generateClassificationReport(y_test,y_pred):
    print(classification_report(y_test,y_pred))
    print(confusion_matrix(y_test,y_pred))    
    print('accuracy is ', accuracy_score(y_test,y_pred))

df = pd.read_csv("/content/drive/MyDrive/BDC/cramers-train.csv", sep=",")
# drop yang tidak dibutuhkan
df = df.drop(['Unnamed: 0',
 'kodeICD_huruf_A',
 'kodeICD_huruf_B',
 'kodeICD_huruf_C',
 'kodeICD_huruf_D',
 'kodeICD_huruf_E',
 'kodeICD_huruf_F',
 'kodeICD_huruf_G',
 'kodeICD_huruf_H',
 'kodeICD_huruf_I',
 'kodeICD_huruf_J',
 'kodeICD_huruf_K',
 'kodeICD_huruf_L',
 'kodeICD_huruf_M',
 'kodeICD_huruf_N',
 'kodeICD_huruf_O',
 'kodeICD_huruf_P',
 'kodeICD_huruf_Q',
 'kodeICD_huruf_R',
 'kodeICD_huruf_S',
 'kodeICD_huruf_T',
 'kodeICD_huruf_U',
 'kodeICD_huruf_V',
 'kodeICD_huruf_W',
 'kodeICD_huruf_X',
 'kodeICD_huruf_Y',
 'kodeICD_huruf_Z'], axis=1)

y = df['status_pulang']
df = df.drop(['status_pulang'], axis=1)

X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.1)

test = pd.read_csv("/content/drive/MyDrive/BDC/cramers-test.csv", sep=",")

test = test.rename(columns={'jenis_kunjungan_enc': 'jenis_kunjungan', 
                            'jenis_poli_1': 'jenis_poli_1.0',
                            'jenis_poli_12': 'jenis_poli_12.0',
                            'jenis_poli_13': 'jenis_poli_13.0',
                            'kode_ICD3_enc': 'kode_ICD3',
                            'kode_ICD4_enc': 'kode_ICD4'})

j = pd.read_csv('/content/drive/MyDrive/BDC/BDC Satria Data 2022/submission.csv')
j.head()

j = j.rename(columns={'Unnamed: 0': 'no'})
j.head()

"""## Voting Classifier"""

from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import RandomForestClassifier
import lightgbm as lgb
from sklearn.linear_model import LogisticRegression
from imblearn.ensemble import BalancedBaggingClassifier

rf = RandomForestClassifier(n_estimators=50)
lgbm = lgb.LGBMClassifier(max_depth=6, num_iterations=1000, num_leaves=50)
bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=2), n_estimators=10,random_state=2,n_jobs=2)
# lr=LogisticRegression(max_iter=1000)

model=VotingClassifier(estimators=[('lgbm',lgbm),('rf',rf),('bbc',bbc)],voting='soft')
model.fit(X_train, y_train)
acc1 = []
target_pred = model.predict(X_test)
generateClassificationReport(y_test,target_pred)
acc1.append(accuracy_score(y_test,target_pred))

print("\n F1 Score: ", f1_score(y_test, target_pred))
print("\n Recall: ", recall_score(y_test, target_pred))
print("\n Accuracy: ", stat.mean(acc1))

test = test.drop(['Unnamed: 0',
 'kodeICD_huruf_A',
 'kodeICD_huruf_B',
 'kodeICD_huruf_C',
 'kodeICD_huruf_D',
 'kodeICD_huruf_E',
 'kodeICD_huruf_F',
 'kodeICD_huruf_G',
 'kodeICD_huruf_H',
 'kodeICD_huruf_I',
 'kodeICD_huruf_J',
 'kodeICD_huruf_K',
 'kodeICD_huruf_L',
 'kodeICD_huruf_M',
 'kodeICD_huruf_N',
 'kodeICD_huruf_O',
 'kodeICD_huruf_P',
 'kodeICD_huruf_Q',
 'kodeICD_huruf_R',
 'kodeICD_huruf_S',
 'kodeICD_huruf_T',
 'kodeICD_huruf_U',
 'kodeICD_huruf_V',
 'kodeICD_huruf_W',
 'kodeICD_huruf_X',
 'kodeICD_huruf_Y',
 'kodeICD_huruf_Z'], axis=1)

result = model.predict(test)

j['Status'] = result
j.no = j.no.astype(str)
j.FKP02 = j.FKP02.astype(str)
j.info()